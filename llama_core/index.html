<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Llama Core, abbreviated as `llama-core`, defines a set of APIs. Developers can utilize these APIs to build applications based on large models, such as chatbots, RAG, and more."><title>llama_core - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-46f98efaafac5295.ttf.woff2,FiraSans-Regular-018c141bf0843ffd.woff2,FiraSans-Medium-8f9a781e4970d388.woff2,SourceCodePro-Regular-562dcc5011b6de7d.ttf.woff2,SourceCodePro-Semibold-d899c5a5c4aeb14a.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../static.files/normalize-76eba96aa4d2e634.css"><link rel="stylesheet" href="../static.files/rustdoc-5ca6ca2a1f83705a.css"><meta name="rustdoc-vars" data-root-path="../" data-static-root-path="../static.files/" data-current-crate="llama_core" data-themes="" data-resource-suffix="" data-rustdoc-version="1.82.0-nightly (c1a6199e9 2024-07-24)" data-channel="nightly" data-search-js="search-d234aafac6c221dd.js" data-settings-js="settings-4313503d2e1961c2.js" ><script src="../static.files/storage-118b08c4c78b968e.js"></script><script defer src="../crates.js"></script><script defer src="../static.files/main-d2fab2bf619172d3.js"></script><noscript><link rel="stylesheet" href="../static.files/noscript-df360f571f6edeae.css"></noscript><link rel="alternate icon" type="image/png" href="../static.files/favicon-32x32-422f7d1d52889060.png"><link rel="icon" type="image/svg+xml" href="../static.files/favicon-2c020d218678b618.svg"></head><body class="rustdoc mod crate"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../llama_core/index.html">llama_core</a><span class="version">0.13.1</span></h2></div><div class="sidebar-elems"><ul class="block"><li><a id="all-types" href="all.html">All Items</a></li></ul><section><ul class="block"><li><a href="#reexports">Re-exports</a></li><li><a href="#modules">Modules</a></li><li><a href="#structs">Structs</a></li><li><a href="#enums">Enums</a></li><li><a href="#functions">Functions</a></li></ul></section></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><h1>Crate <a class="mod" href="#">llama_core</a><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><span class="out-of-band"><a class="src" href="../src/llama_core/lib.rs.html#1-788">source</a> · <button id="toggle-all-docs" title="collapse all docs">[<span>&#x2212;</span>]</button></span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>Llama Core, abbreviated as <code>llama-core</code>, defines a set of APIs. Developers can utilize these APIs to build applications based on large models, such as chatbots, RAG, and more.</p>
</div></details><h2 id="reexports" class="section-header">Re-exports<a href="#reexports" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name" id="reexport.LlamaCoreError"><code>pub use error::<a class="enum" href="error/enum.LlamaCoreError.html" title="enum llama_core::error::LlamaCoreError">LlamaCoreError</a>;</code></div></li></ul><h2 id="modules" class="section-header">Modules<a href="#modules" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="mod" href="chat/index.html" title="mod llama_core::chat">chat</a></div><div class="desc docblock-short">Define APIs for chat completion.</div></li><li><div class="item-name"><a class="mod" href="completions/index.html" title="mod llama_core::completions">completions</a></div><div class="desc docblock-short">Define APIs for completions.</div></li><li><div class="item-name"><a class="mod" href="embeddings/index.html" title="mod llama_core::embeddings">embeddings</a></div><div class="desc docblock-short">Define APIs for computing embeddings.</div></li><li><div class="item-name"><a class="mod" href="error/index.html" title="mod llama_core::error">error</a></div><div class="desc docblock-short">Error types for the Llama Core library.</div></li><li><div class="item-name"><a class="mod" href="models/index.html" title="mod llama_core::models">models</a></div><div class="desc docblock-short">Define APIs for querying models.</div></li><li><div class="item-name"><a class="mod" href="rag/index.html" title="mod llama_core::rag">rag</a></div><div class="desc docblock-short">Define APIs for RAG operations.</div></li><li><div class="item-name"><a class="mod" href="utils/index.html" title="mod llama_core::utils">utils</a></div><div class="desc docblock-short">Define utility functions.</div></li></ul><h2 id="structs" class="section-header">Structs<a href="#structs" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="struct" href="struct.Graph.html" title="struct llama_core::Graph">Graph</a></div><div class="desc docblock-short">Wrapper of the <code>wasmedge_wasi_nn::Graph</code> struct</div></li><li><div class="item-name"><a class="struct" href="struct.Metadata.html" title="struct llama_core::Metadata">Metadata</a></div><div class="desc docblock-short">Model metadata</div></li><li><div class="item-name"><a class="struct" href="struct.MetadataBuilder.html" title="struct llama_core::MetadataBuilder">MetadataBuilder</a></div><div class="desc docblock-short">Builder for the <code>Metadata</code> struct</div></li><li><div class="item-name"><a class="struct" href="struct.PluginInfo.html" title="struct llama_core::PluginInfo">PluginInfo</a></div><div class="desc docblock-short">Version info of the <code>wasi-nn_ggml</code> plugin, including the build number and the commit id.</div></li></ul><h2 id="enums" class="section-header">Enums<a href="#enums" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="enum" href="enum.RunningMode.html" title="enum llama_core::RunningMode">RunningMode</a></div><div class="desc docblock-short">Running mode</div></li></ul><h2 id="functions" class="section-header">Functions<a href="#functions" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="fn" href="fn.get_plugin_info.html" title="fn llama_core::get_plugin_info">get_plugin_info</a></div><div class="desc docblock-short">Get the plugin info</div></li><li><div class="item-name"><a class="fn" href="fn.init_core_context.html" title="fn llama_core::init_core_context">init_core_context</a></div><div class="desc docblock-short">Initialize the core context</div></li><li><div class="item-name"><a class="fn" href="fn.init_rag_core_context.html" title="fn llama_core::init_rag_core_context">init_rag_core_context</a></div><div class="desc docblock-short">Initialize the core context for RAG scenarios.</div></li><li><div class="item-name"><a class="fn" href="fn.running_mode.html" title="fn llama_core::running_mode">running_mode</a></div><div class="desc docblock-short">Return the current running mode.</div></li></ul></section></div></main></body></html>